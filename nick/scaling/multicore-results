#!/usr/bin/env python3

import argparse
import re
import os
import yaml

from string import Template
from collections import OrderedDict

import nbformat as nbf
import pandas as pd


LOG_REGEX = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:\.\d{3})?:\s+')

START_REGEX = re.compile(
    r'Using (?P<cores>\d+) cores on (?P<host>.+)'
    ' to process (?P<events>\d+) events of (?P<file>.+) \[\d+/\d+\]'
)

BENCHMARK_REGEX = re.compile(
    r'(?P<label>\w+)\s+(?P<events>\d+) events\s+'
    'total time =\s+(?P<total_time>\d+\.\d+) s\s+'
    'average event time =\s+(?P<avg_time>\d+\.\d+) ms'
)

ORCH_AVG_TIME_REGEX = re.compile(
    r'Average processing time  =\s+(?P<avg_time>\d+\.\d+) ms'
)


meta_data = {}
results_list = []
results_frame = pd.DataFrame()


def nonblank_lines(f):
    for line in f.readlines():
        line = LOG_REGEX.sub('', line.strip())
        if line:
            yield line


def parse_global_block(line):
    global meta_data

    def parse_meta(key, regex, line):
        match = re.match(regex, line)
        if match:
            meta_data[key] = match.group(1)

    if 'version' not in meta_data:
        parse_meta('version', r'CLARA version += (\S+)', line)
        return False

    if 'date' not in meta_data:
        parse_meta('date', r'Start time += (\d{4}-\d{2}-\d{2})', line)
        return False

    if 'host' not in meta_data:
        parse_meta('host', r'Host += (.+)', line)
        return False

    if 'input_file' not in meta_data:
        parse_meta('input_file', r'Input file += (.+)', line)
        return False

    if 'output_file' not in meta_data:
        parse_meta('output_file', r'Output file += (.+)', line)
        return False

    return True


def parse_time(log_file):
    with open(log_file) as f:
        global_block = True
        benchmark_trial = False
        benchmark_block = False
        for line in nonblank_lines(f):
            if global_block:
                if parse_global_block(line):
                    global_block = False
                continue

            if not benchmark_trial:
                match = START_REGEX.match(line)
                if match:
                    data = OrderedDict()
                    data['Cores'] = int(match.group('cores'))
                    meta_data.setdefault('events', match.group('events'))
                    benchmark_trial = True

            if benchmark_trial and not benchmark_block:
                if line.startswith('Benchmark results:'):
                    benchmark_block = True
                    continue

            if benchmark_block:
                match = BENCHMARK_REGEX.match(line)
                if match:
                    label = match.group('label')
                    data[label] = float(match.group('avg_time'))
                    continue
                match = ORCH_AVG_TIME_REGEX.match(line)
                if match:
                    data['Orchestrator'] = float(match.group('avg_time'))
                    results_list.append(data)
                benchmark_trial = False
                benchmark_block = False

    global results_frame
    results_frame = pd.DataFrame(results_list)
    results_frame = results_frame.groupby('Cores').mean().round(decimals=2)


def write_results(print_csv=True, nb_file=None):
    csv_data = results_frame.to_csv(float_format='%.2f')
    csv_data = csv_data.strip()
    if print_csv:
        print(csv_data)

    def calc_xlim():
        return results_frame.reset_index()['Cores'].max() + 2

    def calc_time_lim():
        t_max = results_frame['TOTAL'].max()
        return int((t_max + 70) / 100 + 1) * 100

    if nb_file:
        nb = nbf.v4.new_notebook()

        data = dict(meta_data)
        data.update({
            'services': results_frame.columns[1:-3].tolist(),
            'csv_data': csv_data,
            'xlim': calc_xlim(),
            'time_lim': calc_time_lim(),
        })
        new_cell = {
            'code': nbf.v4.new_code_cell,
            'markdown': nbf.v4.new_markdown_cell,
        }

        dir_path = os.path.dirname(os.path.realpath(__file__))
        template_path = os.path.join(dir_path, 'multicore-nb.yml')
        with open(template_path) as f:
            template = yaml.safe_load(f)
            for cell in template['notebook']['cells']:
                content = Template(cell['content']).substitute(data).strip()
                nb_cell = new_cell[cell['type']](content)
                nb.setdefault('cells', []).append(nb_cell)

        with open(nb_file, 'w') as f:
            nbf.write(nb, f)


if __name__ == '__main__':

    argparser = argparse.ArgumentParser()
    argparser.add_argument('--nb-file', dest='nb_file', action='store',
                           help='create a Jupyter notebook')
    argparser.add_argument('log_file', help='the multicore-test output')
    args = argparser.parse_args()

    parse_time(args.log_file)
    write_results(print_csv=True, nb_file=args.nb_file)
